{"cells":[{"cell_type":"markdown","metadata":{"id":"DCt0V4XzmDOZ"},"source":["# Importing Dependices"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1dcSKg1Zl38X"},"outputs":[],"source":["import numpy as np \n","import matplotlib.pyplot as plt \n","import os, time, pickle, json \n","from glob import glob \n","from PIL import Image\n","import cv2 \n","from typing import List, Tuple, Dict\n","from statistics import mean \n","from tqdm import tqdm \n","\n","import torch \n","import torch.nn as nn \n","from torchvision import transforms \n","from torchvision.utils import save_image\n","from torch.utils.data import DataLoader "]},{"cell_type":"markdown","metadata":{"id":"3DrYhJtSmGER"},"source":["# Get Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHfKWotsl_ga"},"outputs":[],"source":["!unzip maps.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zV0vHUubl_jC"},"outputs":[],"source":["def read_path(filepath) -\u003e List[str]:\n","    root_path = \"../maps\"\n","    path = os.path.join(root_path, filepath)\n","    dataset = []\n","    for p in glob(path+\"/\"+\"*.jpg\"):\n","        dataset.append(p)\n","    return dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cYchUoSl_mT"},"outputs":[],"source":["MEAN = (0.5, 0.5, 0.5,)\n","STD = (0.5, 0.5, 0.5,)\n","RESIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIJSd6Mrl_pQ"},"outputs":[],"source":["class Transform():\n","    def __init__(self, resize=RESIZE, mean=MEAN, std=STD):\n","        self.data_transform = transforms.Compose([\n","            transforms.Resize((resize, resize)), \n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ])\n","        \n","    def __call__(self, img: Image.Image):\n","        return self.data_transform(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F39eNgFNl_sR"},"outputs":[],"source":["class Dataset(object):\n","    def __init__(self, files: List[str]):\n","        self.files = files \n","        self.trasformer = Transform()\n","        \n","    def _separate(self, img) -\u003e Tuple[Image.Image, Image.Image]:\n","        img = np.array(img, dtype=np.uint8)\n","        h, w, _ = img.shape\n","        w = int(w/2)\n","        return Image.fromarray(img[:, w:, :]), Image.fromarray(img[:, :w, :])\n","    \n","    def __getitem__(self, idx: int) -\u003e Tuple[torch.Tensor, torch.Tensor]:\n","        img = Image.open(self.files[idx])\n","        input, output = self._separate(img)\n","        input_tensor = self.trasformer(input)\n","        output_tensor = self.trasformer(output)\n","        return input_tensor, output_tensor \n","    \n","    def __len__(self):\n","        return len(self.files)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLmyAHrUl_vT"},"outputs":[],"source":["def show_img_sample(img: torch.Tensor, img1: torch.Tensor):\n","    fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n","    ax = axes.ravel()\n","    ax[0].imshow(img.permute(1, 2, 0))\n","    ax[0].set_xticks([])\n","    ax[0].set_yticks([])\n","    ax[0].set_title(\"input image\", c=\"g\")\n","    ax[1].imshow(img1.permute(1, 2, 0))\n","    ax[1].set_xticks([])\n","    ax[1].set_yticks([])\n","    ax[1].set_title(\"label image\", c=\"g\")\n","    plt.subplots_adjust(wspace=0, hspace=0)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVT0qp0ql_yR"},"outputs":[],"source":["train = read_path(\"train\")\n","val = read_path(\"val\")\n","train_ds = Dataset(train)\n","val_ds = Dataset(val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb_J_2Kvl_1Q"},"outputs":[],"source":["show_img_sample(train_ds.__getitem__(1)[0], train_ds.__getitem__(1)[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZkgmHnGl_4a"},"outputs":[],"source":["BATCH_SIZE = 16\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","torch.manual_seed(0)\n","np.random.seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8FOf-XjmjBq"},"outputs":[],"source":["train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"]},{"cell_type":"markdown","metadata":{"id":"18iwlOnKmtLh"},"source":["# Generator Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WX3j7oErmudj"},"outputs":[],"source":["class Block(nn.Module):\n","  def __init__(self,in_channels,out_channels,down=True,act=\"relu\",use_dropout=False):\n","    super().__init__()\n","    self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n","            if down\n","            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n","        )\n","    self.use_dropout=use_dropout\n","    self.dropout=nn.Dropout(0.5)\n","  def forward(self,x):\n","    x=self.conv(x)\n","    return self.dropout(x) if self.use_dropout else x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKRhB-cPmxwT"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, in_channels=3, features=64):\n","        super().__init__()\n","        self.initial_down = nn.Sequential(\n","            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n","            nn.LeakyReLU(0.2),\n","        )\n","        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n","        self.down2 = Block(\n","            features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False\n","        )\n","        self.down3 = Block(\n","            features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False\n","        )\n","        self.down4 = Block(\n","            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n","        )\n","        self.down5 = Block(\n","            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n","        )\n","        self.down6 = Block(\n","            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n","        )\n","        self.bottleneck = nn.Sequential(\n","            nn.Conv2d(features * 8, features * 8, 4, 2, 1), nn.ReLU()\n","        )\n","\n","        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n","        self.up2 = Block(\n","            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n","        )\n","        self.up3 = Block(\n","            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n","        )\n","        self.up4 = Block(\n","            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False\n","        )\n","        self.up5 = Block(\n","            features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False\n","        )\n","        self.up6 = Block(\n","            features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False\n","        )\n","        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n","        self.final_up = nn.Sequential(\n","            nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        d1 = self.initial_down(x)\n","        d2 = self.down1(d1)\n","        d3 = self.down2(d2)\n","        d4 = self.down3(d3)\n","        d5 = self.down4(d4)\n","        d6 = self.down5(d5)\n","        d7 = self.down6(d6)\n","        bottleneck = self.bottleneck(d7)\n","        up1 = self.up1(bottleneck)\n","        up2 = self.up2(torch.cat([up1, d7], 1))\n","        up3 = self.up3(torch.cat([up2, d6], 1))\n","        up4 = self.up4(torch.cat([up3, d5], 1))\n","        up5 = self.up5(torch.cat([up4, d4], 1))\n","        up6 = self.up6(torch.cat([up5, d3], 1))\n","        up7 = self.up7(torch.cat([up6, d2], 1))\n","        return self.final_up(torch.cat([up7, d1], 1))"]},{"cell_type":"markdown","metadata":{"id":"gN8ACKM8mtQz"},"source":["# Discriminator Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Md4Sg-tlmqWT"},"outputs":[],"source":["# from torch.nn.modules.activation import LeakyReLU\n","class ConvBlock(nn.Module):\n","  def __init__(self,in_channels,out_channels,stride=2):\n","    super().__init__()\n","    self.conv_layer=nn.Sequential(\n","        nn.Conv2d(in_channels,out_channels,4,stride,bias=False,padding_mode='reflect'),\n","        nn.BatchNorm2d(out_channels),\n","        nn.LeakyReLU(0.2)\n","    )\n","  def forward(self,x):\n","    return self.conv_layer(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFl5eaXfmjE6"},"outputs":[],"source":["class Discriminator(nn.Module):\n","  def __init__(self,\n","               in_channels=3):\n","    super().__init__()\n","    self.model=nn.Sequential(\n","        nn.Conv2d(in_channels*2,64,kernel_size=4,stride=2,padding_mode=\"reflect\",),\n","        nn.LeakyReLU(0.2),\n","        ConvBlock(64,128,stride=2),\n","        ConvBlock(128,256,stride=2),\n","        ConvBlock(256,512,stride=1),\n","        nn.Conv2d(512,1,kernel_size=4,stride=1,padding=1,padding_mode=\"reflect\"),\n","        nn.Sigmoid()\n","    )\n","  def forward(self,x,y):\n","    x=torch.cat([x,y],dim=1)\n","    return self.model(x)"]},{"cell_type":"markdown","metadata":{"id":"3qJHPNgXm_47"},"source":["# Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1RdLU8kmjIB"},"outputs":[],"source":["def train_fn(train_dl, G, D, criterion_bce, criterion_mae, optimizer_g, optimizer_d):\n","    G.train()\n","    D.train()\n","    LAMBDA = 100.0\n","    total_loss_g, total_loss_d = [], []\n","    for i, (input_img, real_img) in enumerate(tqdm(train_dl)):\n","        input_img = input_img.to(device)\n","        real_img = real_img.to(device)\n","        \n","        real_label = torch.ones(input_img.size()[0], 1, 2, 2)\n","        fake_label = torch.zeros(input_img.size()[0], 1, 2, 2)\n","        # Generator \n","        fake_img = G(input_img)\n","        fake_img_ = fake_img.detach() # commonly using \n","        out_fake = D(fake_img, input_img)\n","        loss_g_bce = criterion_bce(out_fake, real_label) # binaryCrossEntropy\n","        loss_g_mae = criterion_mae(fake_img, real_img) # MSELoss\n","        loss_g = loss_g_bce + LAMBDA * loss_g_mae \n","        total_loss_g.append(loss_g.item())\n","        \n","        optimizer_g.zero_grad()\n","        optimizer_d.zero_grad()\n","        loss_g.backward(retain_graph=True)\n","        optimizer_g.step()\n","        # Discriminator\n","        out_real = D(real_img, input_img)\n","        loss_d_real = criterion_bce(out_real, real_label)\n","        out_fake = D(fake_img_, input_img)\n","        loss_d_fake = criterion_bce(out_fake, fake_label)\n","        loss_d = loss_d_real + loss_d_fake \n","        total_loss_d.append(loss_d.item())\n","        \n","        optimizer_g.zero_grad()\n","        optimizer_d.zero_grad()\n","        loss_d.backward()\n","        optimizer_d.step()\n","    return mean(total_loss_g), mean(total_loss_d), fake_img.detach().cpu() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRXfCe7ZmjLE"},"outputs":[],"source":["def saving_img(fake_img, e):\n","    os.makedirs(\"generated\", exist_ok=True)\n","    save_image(fake_img, f\"generated/fake{str(e)}.png\", range=(-1.0, 1.0), normalize=True)\n","    \n","def saving_logs(result):\n","    with open(\"train.pkl\", \"wb\") as f:\n","        pickle.dump([result], f)\n","        \n","def saving_model(D, G, e):\n","    os.makedirs(\"weight\", exist_ok=True)\n","    torch.save(G.state_dict(), f\"weight/G{str(e+1)}.pth\")\n","    torch.save(D.state_dict(), f\"weight/D{str(e+1)}.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Py-yROLomjOT"},"outputs":[],"source":["def show_losses(g, d):\n","    fig, axes = plt.subplots(1, 2, figsize=(14,6))\n","    ax = axes.ravel()\n","    ax[0].plot(np.arange(len(g)).tolist(), g)\n","    ax[0].set_title(\"Generator Loss\")\n","    ax[1].plot(np.arange(len(d)).tolist(), d)\n","    ax[1].set_title(\"Discriminator Loss\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAhurCS1l_7Z"},"outputs":[],"source":["def train_loop(train_dl, G, D, num_epoch, lr=0.0002, betas=(0.5, 0.999)):\n","    G.to(device)\n","    D.to(device)\n","    optimizer_g = torch.optim.Adam(G.parameters(), lr=lr, betas=betas)\n","    optimizer_d = torch.optim.Adam(D.parameters(), lr=lr, betas=betas)\n","    criterion_mae = nn.L1Loss()\n","    criterion_bce = nn.BCEWithLogitsLoss()\n","    total_loss_d, total_loss_g = [], []\n","    result = {}\n","    \n","    for e in range(num_epoch): #range' is deprecated Use 'value_range'? didn't work\n","        loss_g, loss_d, fake_img = train_fn(train_dl, G, D, criterion_bce, criterion_mae, optimizer_g, optimizer_d)\n","        total_loss_d.append(loss_d)\n","        total_loss_g.append(loss_g)\n","        saving_img(fake_img, e+1)\n","        \n","        if e%10 == 0:\n","            saving_model(D, G, e)\n","    try:\n","        result[\"G\"] = total_loss_d \n","        result[\"D\"] = total_loss_g \n","        saving_logs(result)\n","        show_losses(total_loss_g, total_loss_d)\n","        saving_model(D, G, e)\n","        print(\"successfully save model\")\n","    finally:\n","        return G, D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEYHGlakl_-7"},"outputs":[],"source":["G = Generator()\n","D = Discriminator()\n","EPOCH = 10 \n","trained_G, trained_D = train_loop(train_dl, G, D, EPOCH)"]},{"cell_type":"markdown","metadata":{"id":"7LnTM5SDnQGa"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFjWJ_CRmACL"},"outputs":[],"source":["def load_model(name):\n","    G = Generator()\n","    G.load_state_dict(torch.load(f\"weight/G{name}.pth\", map_location={\"cuda:0\": \"cpu\"}))\n","    G.eval()\n","    return G.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gxxm66MgnOaL"},"outputs":[],"source":["def train_show_img(name, G):\n","#     G = load_model(name)\n","    root = \"generated\"\n","    fig, axes = plt.subplots(int(name), 1, figsize=(12, 18))\n","    ax = axes.ravel()\n","    for i in range(int(name)):\n","        filename = os.path.join(root, f\"fake{str(i+1)}.png\")\n","        ax[i].imshow(Image.open(filename))\n","        ax[i].set_xticks([])\n","        ax[i].set_yticks([])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7edAQwISnOdM"},"outputs":[],"source":["def de_norm(img):\n","    img_ = img.mul(torch.FloatTensor(STD).view(3, 1, 1))\n","    img_ = img_.add(torch.FloatTensor(MEAN).view(3, 1, 1)).detach().numpy()\n","    img_ = np.transpose(img_, (1, 2, 0))\n","    return img_ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jQmmCYPnOf6"},"outputs":[],"source":["def evaluate(val_dl, name, G):\n","    with torch.no_grad():\n","        fig, axes = plt.subplots(6, 8, figsize=(12, 12))\n","        ax = axes.ravel()\n","#         G = load_model(name)\n","        for input_img, real_img in tqdm(val_dl):\n","            input_img = input_img.to(device)\n","            real_img = real_img.to(device)\n","            \n","            fake_img = G(input_img)\n","            batch_size = input_img.size()[0]\n","            batch_size_2 = batch_size * 2 \n","            \n","            for i in range(batch_size):\n","                ax[i].imshow(input_img[i].permute(1, 2, 0))\n","                ax[i+batch_size].imshow(de_norm(real_img[i]))\n","                ax[i+batch_size_2].imshow(de_norm(fake_img[i]))\n","                ax[i].set_xticks([])\n","                ax[i].set_yticks([])\n","                ax[i+batch_size].set_xticks([])\n","                ax[i+batch_size].set_yticks([])\n","                ax[i+batch_size_2].set_xticks([])\n","                ax[i+batch_size_2].set_yticks([])\n","                if i == 0:\n","                    ax[i].set_ylabel(\"Input Image\", c=\"g\")\n","                    ax[i+batch_size].set_ylabel(\"Real Image\", c=\"g\")\n","                    ax[i+batch_size_2].set_ylabel(\"Generated Image\", c=\"r\")\n","            plt.subplots_adjust(wspace=0, hspace=0)\n","            break "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-er-Zw0nOi9"},"outputs":[],"source":["train_show_img(5, trained_G)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lgd59n9nOl6"},"outputs":[],"source":["evaluate(val_dl, 5, trained_G)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPN+3T0mdfP/QT0B00bOau2","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}